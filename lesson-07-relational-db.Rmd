# Working with relational data & databases {#relationaldb}

```{r setup, include=FALSE}
les <- 7
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction
We spend quite some time now on learning how to visualise, analyse, and describe data. But where do we get the data? In DAUR2 we have seen how to [access data from the ](https://datascience.hu.nl/rsconnect/dsfb1-daur2-reader/lesson-4-entrez-combining-biological-datasets.html) and how to use [biomaRt to access ensembl and GEO(Gene Expression Omnibus)](https://datascience.hu.nl/rsconnect/dsfb1-daur2-reader/lesson-3-acquiring-biological-data-from-databases-biomart-geoquery.html). We used the  Bioconductor project, an open source software repository specifically for high-throughput biological assay data.

We have practised a bit with combining data from different sources in DAUR2, and we will build on that experience in this lesson.

### Relational data
It is quite rare for a data analysis to use only one table of data. Suppose you investigate the effects of a certain drug on behaviour of rats in a maze. You may have blood levels of the drug at certain times, some automatic recording of movements, maybe you weighted them before every experiment, etc. You may enter some of these values in excel, but other values about the same rats will be stored in different formats or in different files, such as the video recordings or descriptive statistics of these video recordings (average time in maze, number of mistakes etc etc). Still, you will want to look at all this information combined. Collectively, these tables of data are called *relational data*.

For example, we used the NYflights13 package before to look at relational data in DAUR1. It contains several tables with information, which are related. In the diagram below, which we borrowed from [r4ds by Hadley Wickham and Garrett Grolemund](https://r4ds.had.co.nz/relational-data.html), some of the variables in the different tables are depicted:

![nyflights relations example](https://d33wubrfki0l68.cloudfront.net/245292d1ea724f6c3fd8a92063dcd7bfb9758d02/5751b/diagrams/relational-nycflights.png)
You can see that some variables in one table are present or translate to variables in other tables. Therefore, the tables can be combined. If you want more information on the plane used on a flight in the `flights` table, you can use it's tailnumber to look it up in the `planes` table (or actually, have R do it for you by **joining** the tables, don't look it up manually obviously...)


### Remember `tidy` data?

The nyflights tables are really nice and tidy. You have used them before to practice joining tibbles, and they are joined quite easily.

Quite often if you download or gather  data and want to join two datasets, you may need to reshape them. Usually, having or transforming your data in the `tidy` shape is a good practice if you want to perform subsequent joins.

<div class="tip">
Tidy data means:

 1. All variables in their own column
 1. All observations in their own row
 1. Every cell contains a single observations

</div>

You may have used `gather()` and `spread()` in DAUR1 to make tibbles tidy or untidy depending on your needs. They have been updated to be a bit more user friendly! The new functions are called `pivot_longer` and `pivot_wider`:

Here is an example with pivot_longer() :
```{r, message=FALSE, error=FALSE}
library(palmerpenguins)
library(tidyverse)

penguins %>% 
  tidyr::pivot_longer(contains("_"), # measurement cols
                      names_to = c("variable_name"), 
                      values_to = "value")
```

Or perhaps (see the difference?):
```{r, message=FALSE, error=FALSE}
penguins_long <- penguins %>% 
  tidyr::pivot_longer(contains("_"), # measurement cols
                      names_to = c("part", "measure", "unit"), 
                      names_sep = "_")

penguins_long
```

<div class="question">
##### Exercise `r les` {-} 
What is the first variable in the `penguins_long` dataframe printed above?

</div>

<details><summary>Click for the answer</summary>
species (just to make sure you still know which parts of a tibble/dataframe are variables)
</details>

</br>

Let's get it back to wide again:

```{r, message=FALSE, error=FALSE}
penguins_long %>% 
  tidyr::pivot_wider(names_from = c("part", "measure", "unit"), # pivot these columns
                     values_from = "value", # take the values from here
                     names_sep = "_") # combine col names using an underscore
```


Oh, we're in trouble. Read the error message. 

<div class="question">
##### Exercise `r les` {-} 
What happened? Can you think of a way we could have **prevented** this error a couple of steps before? Try it!

</div>

<details><summary>Click for the answer</summary>

R isn't sure where to put the data anymore, as there are duplicates. Every measurement was not marked by some unique code and there are (for instance) 7 male Adelie penguin measured on Torgersen in 2007, and 5 female Adelie penguin measured on Biscoe in 2007. Now what?

We need to be able to identify each measurement from the other ones based on something else. 

For instance, just number all the measurements in the first place:
(note that this is just an example of a solution, anything you came up with that works, works!)

```{r}
# give each measured penguin a number
penguins_with_id <- penguins %>%  mutate(id=seq(nrow(.)))

# make the data long again
penguins_long_ided <- penguins_with_id %>% 
      tidyr::pivot_longer(contains("_"), # measurement cols
                      names_to = c("part", "measure", "unit"), 
                      names_sep = "_")

# and wide again
penguins_long_ided %>% 
    tidyr::pivot_wider(names_from = c("part", "measure", "unit"), 
                     values_from = "value", 
                     names_sep = "_") 

```
</details>


### Joining data in databases

Joining operations are frequently used to increase or reduce the amount of data you have. To join tables you need some shared information to uniquely identify each observation: a `key`. In simple cases, one single variable is sufficient to identify each measurement. Each car in the Netherlands is identified by its licence plate. And for example, our fictional rabbit ear length dataset could look like this, with a key variable in the first column:

```{r rabbittable, message=FALSE, error=FALSE, echo=FALSE}
library(kableExtra)
rabbitdata <- tibble(
  rabbit_id = paste0("rabbit_",seq(1,(10*365)/21+1)),
  time=seq(from=Sys.Date()-(10*365), to=Sys.Date(), by=21 ), 
  oorlengte=runif((10*365)/21+1,min = 6, max = 10)
)

kbl(head(rabbitdata),caption = "Rabbit ear length data") %>%
  kable_styling(bootstrap_options = "striped", 
                full_width = F, 
                position = "left")

```

Let's check if they are indeed unique:

```{r}
rabbitdata %>% 
  count(rabbit_id) %>% 
  filter(n > 1)
```

<div class="question">
##### Exercise `r les` {-} 
Read the output. Why does this give an empty tibble? Is that a good thing?
</div>

<details><summary>Click for the answer</summary>
There are no rabbit_id's that are used twice in the dataset. That is exactly what we wanted.
</details>
</br>

As you have seen in the previous paragraph, the `penguins` dataset in palmerpenguins does not have one key variable. There is no unique code to identify each measured penguin. If two separate penguins by some extreme coincidence have the exact same metrics (same year, same species, island, same bill length, same body mass, same everything), their rows would be identical.

```{r, warning=FALSE, message=FALSE}
penguins %>% head()
```

You cannot identify an observation by using a single variable ("this penguins bill length is 41.1").

But if you combine several columns, you can identify a penguin (e.g. "this penguin has bill length 39.5, flipper length 186 and is female"). As you have seen, not just any combination of variables will work (species + island + sex + year was not enough: "this male Adelie penguin was measured on Torgersen in 2007" will yield you 7 possible penguins.).

Suppose you have some dataset and want to add a key value, the easiest way is just to number your measurements as we did before in the example solution to one of the previous questions (I like my ID's to be in the first few columns, so I use ".before=") :

```{r, warning=FALSE, message=FALSE}
penguins %>% mutate(penguin_id = row_number(),.before = species)
```

In this example we made a key value for each penguin. But when searching through a database, a key can also be a combination of attributes (columns). As long as this combination lets you uniquely identify records (rows) in the table.

Keys can be used to join different tables. You have used this before in DAUR1.

<div class="question">
##### Exercise `r les` {-} 
Let's refresh your memory. Take the `penguins` dataset. 

As we all know, Adelie penguins love peanut butter, Chinstrap penguins prefer cheese and Gentoo penguins do everything for chocolate.

Here is a dataset describing food preference:
```{r}
food_preference <-
  tibble(
    penguin_species = c("Adelie", "Chinstrap", "Gentoo"),
    favorite_food = c("peanut butter", "cheese", "chocolate")
  )
```

Join this dataset with the `penguins` dataset in such a way that *favorite_food* becomes a variable within `penguins`.
What is/are the **key** variables?

</div>

<details><summary>Click for the answer</summary>
```{r, eval=F}
left_join(
  penguins, food_preference, by = c("species" = "penguin_species")
)
```

The key variables are species and penguin_species.
</details>
</br>

<div class="question">
##### Exercise `r les` {-} 
Now make a new tibble containing only the information on penguin species, sex and bill length measured in 2009 using `filter` and `select`.
</div>

<details><summary>Click for the answer</summary>

You should really revisit [DAUR1, this lesson here in the link](https://datascience.hu.nl/rsconnect/dsfb1-daur1-reader/lesson-5-data-wrangling.html) if you forgot how to do this. As you filter on year, but year is not part of the selection, filter first, select second.
</details>
</br>

<mark>## Perhaps some more tidyverse joining but only if we have time left</mark>




## SQL
Now suppose you want to access some other, perhaps company specific database, which does not have it's neatly described bioconductor package or is included in an R package. The lingua franca for retrieving (and transform, manage and store) information from relational databases is Structured Query Language - or SQL . You can pronounce this "S-Q-L" (in English) or "sequel", both are used. It was already developed in the 60's and has grown into a very accessible and popular language (with a few dialects..) to communicate with databases.

Watch [this GLITCH video on SQL](https://www.youtube.com/watch?v=27axs9dO7AE), because it is very clear and uses LEGO! (seriously, watch it, it is only 4 minutes.)

### Relational data
We have discussed relational databases in DAUR2, but what were they again? In a relational database, data is organised in -mostly- tables that can be linked to each other based on data that is available in both tables (remember the `left_join()` function?). These tables are called **relations**, and columns are not called variables but **attributes or fields**, and rows are called **tuples or records**. Luckily, SQL just calls them rows, columns and tables. But make note of the terms because you may encounter them when diving in databases.

```{r examplefig,  echo=FALSE, out.width = "300px", fig.cap="Relational databases and their preference for not just naming rows 'rows'."}
knitr::include_graphics(
"https://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Relational_database_terms.svg/350px-Relational_database_terms.svg.png"
)
```



## Creating a PostgreSQL database in DBeaver
In order 




## Using R to work with PostgreSQL databases
On the server th


##### Exercise `r les` {-}
## <mark> EXERCISE 1 </mark> {-} 
 
**TIPS**

 - Be aware, the flu and dengue data contains metadata that should be stripped from the data on load.
 - Think of a way to create valid country names that fit with the gapminder data.
 - Use `readr::write_csv()` and `readr::write_rds()` to write cleaned tables to disk
 
 a) Load the flu ("./data/flu_data.csv), the dengue ("./data/dengue_data.csv) and the gapminder (`{dslabs}` package) into three separate dataframes in R
 
 b) Check if they are in the right shape. Is the data in the 'tidy' format? If not change the format to 'tidy' 
 
 c) Change the `country` and `date` variables of the three tables so that they coincide in terms of data type, class and values 
 
 d) Store the three tables as seperate (so six in total) .csv and .rds files.



    In R, maak van de wide tables een long/stacked formaat met {dplyr} (pivot longer()). Sla de nieuwe tabellen op als rds (R binary)
    In Dbeaver creeer een nieuwe lege PostgreSQL database "workflowsdb"
    Met behulp van R script ({RPostgreSQL} insert de twee tabellen in de "workflowsdb" database
    Inspecteer de content van de tabellen met SQL (in DBeaver) en in R met behulp van {dplyr} en {dbplyr}
    Laadt de gapminder data en pas de data in R zo aan dat een join met de dengue en flue data in de databse mogelijk is (bijvoorbeeld landnamen hetzelfde maken)
    Sla deze clean gapminder data op in de "workflowsdb" database
    Doe een aantal joins en inspecties op de data met SQL (bijvoorbeeld in DBeaver of met dplyr.
    Genereer een grote tabel joined en exporteer die van de database naar de R sessie
    Maak een aantal visualisatie op basis van de joined data met ggplot2 etc...


## Portfolio assignment `r paste0(les, " ")` {-}

## Resources and references
Part of the materials in this chapter were reproduced in a an adapted form from [@r4ds]. DBeaver tutorials from youtube (see \@ref(resources)). Tutorials on using the package `{RPostgreSQL}` can also be found in \@ref(resources)
